{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d910fa5-92b3-4fe2-8e4e-db8fce931d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d81f5507-a13c-4a4e-a35c-49641d8e5ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 48 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "#os.environ['HF_HOME'] = '/data/users/ugarg/hf/hf_cache/'\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/data/users/ugarg/hf/hf_cache/'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "\n",
    "#sys.path.append('../../..')\n",
    "sys.path.append('../')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=False)\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from transformers import AdamW, AutoTokenizer,  AutoModel\n",
    "from torch.nn.functional import one_hot\n",
    "from collections import Counter\n",
    "from torch.optim import AdamW, Adam\n",
    "from transformers import get_scheduler, get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(42)\n",
    "import joblib\n",
    "import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from utils.get_data_and_splits import LoadData\n",
    "from utils.params import get_roberta_params, get_xlm_params\n",
    "from utils.model import Model\n",
    "from utils.utils import checkpoint_builder\n",
    "from utils.faiss_utils import create_and_store_index, get_top_n_accuracy\n",
    "from utils.predict import prep_model, predict_on_batch #\n",
    "\n",
    "from CreatePytorchDataset import TrainDataset, ValDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d14dff2-f533-4b80-9efc-da08c9e2048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 1141099/1141099 [00:22<00:00, 49652.52it/s]\n",
      "100%|██████████████████████████████████| 31444/31444 [00:00<00:00, 47978.78it/s]\n",
      "100%|████████████████████████████████████| 4593/4593 [00:00<00:00, 46671.01it/s]\n",
      "100%|████████████████████████████████████| 4529/4529 [00:00<00:00, 46408.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of Train before drop duplicates - 361167\n",
      "Len of Val before drop duplicates - 4219\n",
      "Len of Test before drop duplicates - 4227\n",
      "Len of Train - 359767\n",
      "Len of Val - 4219\n",
      "Len of Test - 4227\n"
     ]
    }
   ],
   "source": [
    "loaddata = LoadData()\n",
    "train, val, test = loaddata.get_data(\"/data/users/abose1/Capstone/Dictionary_and_Word_Embeddings/data/static_wiki.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7321c1c6-a93f-4e71-9d39-c3dd57e09ca3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_129868/3665049672.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../clean_data/train.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../clean_data/val.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../clean_data/test.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/users/ugarg/anaconda3/envs/pytorenv/lib/python3.9/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    585\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/users/ugarg/anaconda3/envs/pytorenv/lib/python3.9/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[0;32m/data/users/ugarg/anaconda3/envs/pytorenv/lib/python3.9/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1210\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/users/ugarg/anaconda3/envs/pytorenv/lib/python3.9/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDArrayWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# Be careful to register our new method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/users/ugarg/anaconda3/envs/pytorenv/lib/python3.9/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, unpickler)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# Manage array subclass case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/users/ugarg/anaconda3/envs/pytorenv/lib/python3.9/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(self, unpickler)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# The array contained Python objects. We need to unpickle the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train = joblib.load('../clean_data/train.joblib')\n",
    "val = joblib.load('../clean_data/val.joblib')\n",
    "test = joblib.load('../clean_data/test.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48a3246-e33f-433a-a945-56c09339d39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e4345-4e38-43d0-b799-38ae038f6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a0c1c3-d4e3-452e-84ac-a8c5a273cedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092a5cf6-67a3-4fe8-8a61-f8b4f8fd4f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Len of train = {len(train)}\")\n",
    "print(f\"Len of dev = {len(val)}\")\n",
    "print(f\"Len of test = {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1723d4-7488-4f9f-8347-53cd43a2a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cabcbaa0-7c5a-43bc-97ae-261b6a5502d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_roberta_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82d49cee-cf19-488a-9240-854da43c4c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_checkpoint': 'roberta-large',\n",
       " 'source_column': 'gloss',\n",
       " 'max_len': 150,\n",
       " 'batch_size': 64,\n",
       " 'dropout': 0.3,\n",
       " 'learning_rate': 0.0001,\n",
       " 'num_epochs': 150,\n",
       " 'early_stopping_limit': 5,\n",
       " 'device': 'cuda:0',\n",
       " 'loss_fn_name': 'cosine',\n",
       " 'emb_type': 'fasttext',\n",
       " 'use_adapters': True,\n",
       " 'resume_from_checkpoint': True,\n",
       " 'output_size': 300,\n",
       " 'knn_measure': 'cosine'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896fabd6-0cc8-414c-a79c-69bd6d30d8da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca89254d-a13d-4b2f-923e-78f6a86e36b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Indexing...\n",
      "Creating FAISS Index...\n",
      "FAISS Index Creation Done...\n"
     ]
    }
   ],
   "source": [
    "create_and_store_index(\n",
    "    params['emb_type'], params['knn_measure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dae01d2b-91bf-48c0-8a07-6293bd49c287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Tokenizer: roberta-large ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################\n",
    "#   tokenizer\n",
    "##################\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = params['model_checkpoint']\n",
    "print(f'\\nLoading Tokenizer: {model_checkpoint} ...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d3307-d205-449a-8e00-88fa679e3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['word','gloss', 'fasttext']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c808d18-a888-416f-b88e-5ff8d22848cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a88d735-da20-4184-9c54-fcd43cc1f5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint_path = f\"checkpoints/{params['model_checkpoint']}_model_{params['loss_fn_name']}_loss_{params['emb_type']}_embs_{params['use_adapters']}_adapter.pt\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ebd04e-e0eb-4333-a9ac-65cb0ae064a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4fc8c2-1963-452c-8ae2-25e8c6247c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(\n",
    "    train, \n",
    "    tokenizer, \n",
    "    params['source_column'],\n",
    "    params['max_len'], \n",
    "    params['emb_type']\n",
    ")\n",
    "val_dataset = ValDataset(\n",
    "    val, \n",
    "    tokenizer, \n",
    "    params['source_column'],\n",
    "    params['max_len'], \n",
    "    params['emb_type']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde2885d-ebc6-43a6-acc0-173f489be547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6297ed4e-44a5-4fe9-9b64-5672e0299f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    collate_fn = data_collator,\n",
    "    batch_size = params['batch_size'],\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    collate_fn = data_collator, \n",
    "    batch_size=params['batch_size']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7aedfa-e6a6-4849-abee-8ef64826dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################################\n",
    "#   Load Model\n",
    "####################################\n",
    "\n",
    "print(f\"\\nUsing device {params['device']} for training...\")\n",
    "\n",
    "model = Model(params['model_checkpoint'], \n",
    "              params['output_size'], \n",
    "              params['dropout'], \n",
    "              params['device'], \n",
    "              params['loss_fn_name'], \n",
    "              params['use_adapters'])\n",
    "model.to(params['device'])\n",
    "\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff0aeb90-e0bd-45d5-91b7-601c383cd421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating optimizer with Learning Rate: 0.0001\n",
      "\n",
      "Training for 150 epochs with early stopping set to 5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "####################################\n",
    "#   Create Optimizer\n",
    "####################################\n",
    "print(f\"\\nCreating optimizer with Learning Rate: {params['learning_rate']}\")\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = params['learning_rate'])\n",
    "\n",
    "print(f\"\\nTraining for {params['num_epochs']} epochs with early stopping set to {params['early_stopping_limit']}\\n\\n\")\n",
    "\n",
    "num_train_epochs = params['num_epochs']\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=300,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab03efec-2d3b-483b-9500-043ed3e74192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff39980bdf0a4c5e8f86aa0ba2cbecb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/934350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / 150]\n",
      "\n",
      "Epoch: 0 \tTraining Loss: 0.507712 \tValidation Loss: 0.489098\n",
      "Loss improved saving checkpoint... \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "checkpoint_builder() takes 4 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_83510/2374362690.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m#create checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss improved saving checkpoint... \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mcheckpoint_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: checkpoint_builder() takes 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "early_stopping_counter = 0\n",
    "early_stopping_limit = params['early_stopping_limit']\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    train_loss=0\n",
    "    valid_loss =0\n",
    "    \n",
    "\n",
    "    \n",
    "    print(f\"[Epoch {epoch} / {num_train_epochs}]\")\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        loss, out, actual = model(batch)\n",
    "        #loss = outputs.loss\n",
    "        loss.backward(loss)#, retain_graph = True)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss+= ((1 / (batch_idx + 1)) * (loss.data.item() - train_loss))\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_postfix(loss = train_loss)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    for batch_idx, batch in enumerate(val_dataloader):\n",
    "        with torch.no_grad():\n",
    "            loss, out, actual = model(batch)\n",
    "\n",
    "\n",
    "        labels = actual\n",
    "        predictions = out\n",
    "        \n",
    "        valid_loss+= ((1 / (batch_idx + 1)) * (loss.data.item() - valid_loss))\n",
    "        \n",
    "\n",
    "    print('\\nEpoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "\n",
    "    #early stopping, checkpointing\n",
    "    if valid_loss < best_valid_loss:\n",
    "        early_stopping_counter = 0\n",
    "        best_valid_loss = valid_loss\n",
    "        #create checkpoint\n",
    "        print(\"Loss improved saving checkpoint... \")\n",
    "        checkpoint_builder(model, optimizer, epoch, save_checkpoint_path)\n",
    "\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= early_stopping_limit:\n",
    "            print(f'\\nLoss did not reduce for last {early_stopping_counter} epochs. Stopped training..')\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23782705-b85f-4815-a60d-ac1257682413",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "* Here we load the model from checkpoint\n",
    "* Create Search index\n",
    "    * Created using Test + Val dataset\n",
    "* Get nearest neighbours for dev predictions\n",
    "* Get Average Rank and Top N accuracy\n",
    "    * Average Rank - If the word is not found in nearest 500 words, we make the rank 500 for that word\n",
    "    * Top N - If the word is in Top N nearest neighbours predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7a7b543-7a60-4fda-b3a9-a9eb0b75f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_xlm_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7f07ddb-f95b-4cd2-8f6d-75cb4be5406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Tokenizer: xlm-roberta-large ...\n",
      "Loading from : /data/users/ugarg/capstone/code/Dictionary_and_Word_Embeddings-main/gloss2word/v2/checkpoints/xlm-roberta-large_model_cosine_loss_fasttext_embs_True_adapter0.0001_lr.pt\n",
      "\n",
      "Using device cuda:0 for training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Checkpoint ...\n",
      "Setting Models state to checkpoint...\n",
      "Model state set.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 7, got 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_129868/2036160054.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_collator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaiss_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaiss_idx_word_to_index_lookup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaiss_idx_index_to_word_lookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 7, got 6)"
     ]
    }
   ],
   "source": [
    "tokenizer, model, data_collator, sim, faiss_index, faiss_idx_word_to_index_lookup, faiss_idx_index_to_word_lookup = prep_model(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a655ebb1-78fe-430d-ae00-d63d1e79338c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409580"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(faiss_idx_word_to_index_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f11bb7b-db13-453c-b398-712853d60f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286681"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(faiss_idx_index_to_word_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f1cefa9-7e5f-4883-9a91-6b4d7942c6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "02fdf063-6e73-43f4-a933-a1ea1eac103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use it if text in list\n",
    "NEAREST_NEIGHBOUR_NUM = 409580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3bc5cf3a-cd13-4016-8cd8-a462c7615c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409580"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(faiss_idx_word_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "967cf05b-45f5-4e27-b8c8-4c99974b000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = joblib.load('../clean_data/val.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c28a9cef-35a6-4594-b9c7-56847b84ed2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2f7b9f0b63458aa028c90b15c96c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Rank @409580 : 117252.99981798325\n"
     ]
    }
   ],
   "source": [
    "pred_batch = 50\n",
    "ranks = []\n",
    "for i in tqdm(range(0, len(val), pred_batch)):\n",
    "    x = val.loc[i:i+pred_batch-1]\n",
    "    \n",
    "    preds = predict_on_batch(\n",
    "        x['gloss'].values.tolist(), \n",
    "        tokenizer, model, data_collator, sim, faiss_index, \n",
    "        faiss_idx_word_lookup, NEAREST_NEIGHBOUR_NUM\n",
    "    )\n",
    "    for j in range(len(preds)):\n",
    "        rank = get_rank(x['word'].values[j], preds[j], NEAREST_NEIGHBOUR_NUM)\n",
    "        ranks.append(rank)\n",
    "        \n",
    "    \n",
    "    # print(f\"Gloss: {val.loc[i,'gloss']}\")\n",
    "    # print(f\"Actual Word: {val.loc[i,'word']}\")\n",
    "    # print(f'Predicted: {list(dict.fromkeys(preds))[:5]}')\n",
    "    # print('---\\n')\n",
    "print(f\"Average Rank @{NEAREST_NEIGHBOUR_NUM} : {np.mean(ranks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e696cedd-a25f-47f7-81c8-0d7cf3b4c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "val['pred_rank'] = ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fde62870-859b-4a71-b730-6db6631c0e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa83db7a-ed02-43bd-ad08-b5f555e07ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a427d67a-5d42-4957-8d34-3cbc8dd3d18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f4112086850>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.displot(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "107537a1-144d-46a0-8f0b-4c81897d7e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy is 0.137\n",
      "Top 5 accuracy is 0.221\n",
      "Top 10 accuracy is 0.27\n",
      "Top 50 accuracy is 0.415\n",
      "Top 100 accuracy is 0.479\n"
     ]
    }
   ],
   "source": [
    "for n in [1,5,10,50,100]:\n",
    "    print(f\"Top {n} accuracy is {get_top_n_accuracy(ranks, n)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69e6fda0-b5f7-4217-b612-d4b228d1f229",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"able to turn freely about an axis.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5def1785-f862-4e8f-9342-d899d1911dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict_on_batch(\n",
    "        text, \n",
    "        tokenizer, model, data_collator, sim, faiss_index, \n",
    "        faiss_idx_index_to_word_lookup, 5\n",
    "    )\n",
    "#words = list(dict.fromkeys(preds))[:25]\n",
    "\n",
    "# for word in words:\n",
    "#     gloss = df[df.word==word]['gloss'].values\n",
    "    \n",
    "#     print(f'{word}: \\n{gloss}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d648b1c1-2f72-485e-b85d-b77346f61436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[339900, 328171, 383486,  91375, 209822]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d659b881-aded-4856-8318-28ac163fea96",
   "metadata": {},
   "source": [
    "* Any gloss to word\n",
    "* You give any word - \"bokizona\": the top of a lamp made of wood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c9fe18-0dfe-440c-b5de-e5e377bcf514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use it if text in list\n",
    "# faiss_idx_word_lookup = joblib.load('faiss_idx_word_lookup.joblib')\n",
    "# sim = Similarity()\n",
    "# ranks = []\n",
    "# for i in tqdm(range(len(val))):\n",
    "    \n",
    "#     preds = predict_on_sentence(val.loc[i,'gloss'], sim, faiss_idx_word_lookup)\n",
    "#     rank = get_rank(val.loc[i, 'word'], preds)\n",
    "#     ranks.append(rank)\n",
    "#     # print(f\"Gloss: {val.loc[i,'gloss']}\")\n",
    "#     # print(f\"Actual Word: {val.loc[i,'word']}\")\n",
    "#     # print(f'Predicted: {list(dict.fromkeys(preds))[:5]}')\n",
    "#     # print('---\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "15bf2618-0280-4dba-ad73-5f615a40e670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c059ebb-2abd-4a34-bef8-34894724f38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073b1d01-bdfb-4f26-9495-5fbc97d7c3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2401e984-c73a-4224-88f6-56ec16b701b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>gloss</th>\n",
       "      <th>fasttext</th>\n",
       "      <th>pred_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>mushy</td>\n",
       "      <td>Overly sappy , corny , or cheesy</td>\n",
       "      <td>[-0.0917, -0.4726, -0.0255, 0.0673, 0.1981, 0....</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>emotional</td>\n",
       "      <td>Easily affected by emotion .</td>\n",
       "      <td>[0.2489, 0.0254, 0.2088, -0.1229, 0.375, -0.32...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736</th>\n",
       "      <td>synchronically</td>\n",
       "      <td>In a synchronic way</td>\n",
       "      <td>[0.0917, 0.3119, -0.2979, -0.0922, -0.1644, -0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3877</th>\n",
       "      <td>rebuild</td>\n",
       "      <td>A process or result of rebuilding .</td>\n",
       "      <td>[0.1659, 0.0074, 0.0992, 0.2391, -0.3666, -0.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>jubilation</td>\n",
       "      <td>rejoicing</td>\n",
       "      <td>[0.4779, -0.3126, -0.1331, 0.0347, -0.0798, -0...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>palace</td>\n",
       "      <td>To decorate or ornate .</td>\n",
       "      <td>[-0.0523, -0.415, 0.0576, 0.0265, -0.6142, 0.0...</td>\n",
       "      <td>409580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>write</td>\n",
       "      <td>often used reflexively .</td>\n",
       "      <td>[-0.1804, 0.0429, -0.093, -0.0897, 0.2307, 0.1...</td>\n",
       "      <td>409580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3305</th>\n",
       "      <td>oropharynx</td>\n",
       "      <td>The oral part of the pharynx , reaching from t...</td>\n",
       "      <td>[-0.1871, 0.2104, -0.0528, 0.208, -0.1884, 0.2...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>cardinal</td>\n",
       "      <td>Of or relating to the cardinal directions ( no...</td>\n",
       "      <td>[-0.1016, 0.1126, -0.4016, -0.4115, -0.2766, 0...</td>\n",
       "      <td>409580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>hoofprint</td>\n",
       "      <td>The mark of a hoof .</td>\n",
       "      <td>[0.2603, -0.3164, -0.4397, 0.0254, -0.1064, -0...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word                                              gloss  \\\n",
       "3071           mushy                  Overly sappy , corny , or cheesy    \n",
       "1623       emotional                       Easily affected by emotion .   \n",
       "4736  synchronically                               In a synchronic way    \n",
       "3877         rebuild                A process or result of rebuilding .   \n",
       "2613      jubilation                                         rejoicing    \n",
       "3358          palace                            To decorate or ornate .   \n",
       "5464           write                           often used reflexively .   \n",
       "3305      oropharynx  The oral part of the pharynx , reaching from t...   \n",
       "850         cardinal  Of or relating to the cardinal directions ( no...   \n",
       "2384       hoofprint                               The mark of a hoof .   \n",
       "\n",
       "                                               fasttext  pred_rank  \n",
       "3071  [-0.0917, -0.4726, -0.0255, 0.0673, 0.1981, 0....        639  \n",
       "1623  [0.2489, 0.0254, 0.2088, -0.1229, 0.375, -0.32...         14  \n",
       "4736  [0.0917, 0.3119, -0.2979, -0.0922, -0.1644, -0...          1  \n",
       "3877  [0.1659, 0.0074, 0.0992, 0.2391, -0.3666, -0.0...          1  \n",
       "2613  [0.4779, -0.3126, -0.1331, 0.0347, -0.0798, -0...          5  \n",
       "3358  [-0.0523, -0.415, 0.0576, 0.0265, -0.6142, 0.0...     409580  \n",
       "5464  [-0.1804, 0.0429, -0.093, -0.0897, 0.2307, 0.1...     409580  \n",
       "3305  [-0.1871, 0.2104, -0.0528, 0.208, -0.1884, 0.2...         60  \n",
       "850   [-0.1016, 0.1126, -0.4016, -0.4115, -0.2766, 0...     409580  \n",
       "2384  [0.2603, -0.3164, -0.4397, 0.0254, -0.1064, -0...         20  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c012703-91cf-4505-a386-2bea684730b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "* Full stop\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f5d5d69e-b25c-47b0-ab48-7b7f135c5c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'cardinal' in set([i[1] for i in faiss_idx_word_lookup.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ee650b-7ed2-402a-9f70-329e8f8ba603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90d43d7a-9d57-468f-9164-688e5b79f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3]) \n",
    "a = a / sum(a**2)**0.5\n",
    "b = np.array([.1,1,1]) \n",
    "b = b / sum(b**2)**0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db15c145-56a7-43a8-8905-5703803e791f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26726124, 0.53452248, 0.80178373])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4645673f-ca6c-4a45-b11b-1a843eb03619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07053456, 0.70534562, 0.70534562])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fa01fd0-6fe3-42ba-8e12-9ba777b631a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9614088808864494"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be4efe2-b438-4e2e-a267-d56c89d41cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
